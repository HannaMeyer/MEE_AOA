---
title: "Method of the 'Area of Applicability' (AOA) explained in figures"
subtitle: "Supplement to the paper 'Predicting into unknown space? Estimating the area of applicability of spatial prediction models' (Methods in Ecology and Evolution)"
author: "Hanna Meyer, Edzer Pebesma"
date: "17/04/2021"
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H} 
output:
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, message = FALSE,include = FALSE}
rm(list=ls())
#install_github("HannaMeyer/CAST")
library(virtualspecies)
library(caret)
library(CAST)
library(viridis)
library(gridExtra)
library(knitr)
library(grid)
library(latticeExtra)
library(plotrix)
library(scatterplot3d)
library(ggplot2)
library(randomForest)
library(quantregForest)
library(RColorBrewer)

rmse <- function(pred,obs){sqrt( mean((pred - obs)^2, na.rm = TRUE) )}
```


```{r settings,include = FALSE}
npoints <- 150 # number of training samples
meansPCA <- c(3, -1) # means of the gaussian response functions to the 2 axes
sdPCA <- c(2, 2) # sd's of the gaussian response functions to the 2 axes
simulateResponse <- c("bio2","bio5","bio10", "bio13",
                      "bio14","bio19") # variables used to simulate the response
studyarea <- c(-15, 65, 30, 75) # extent of study area. Default: Europe
seed <- 1 
var1="bio1"
var2="bio19"
```

# Introduction
This document is a supplement to the paper 'Predicting into unknown space? Estimating the area of applicability of spatial prediction models'. It visualizes the idea and workflow of the method to estimate the area of applicability (AOA) of prediction models. 
Note that the purpose of this document is to visualize the idea of the method. Hence, the dataset is small and not a scientifically meaningful prediction task.
For application in more realistic applications, as well as for detailed explanations please see the manuscript.
For reproducing this document, please use the Rmd file available at \url{https://github.com/HannaMeyer/MEE_AOA}.

# General problem of random forests in "unknown environments"

```{r Fig_predintervals,include = FALSE}
# simulate example data for a linear model:
f <- function(x, z = 0.8, b = 0, e = 0.3) {
  z * x+ b + rnorm(length(x)) * e
}
set.seed(131)
x <- sort(runif(30, 0.7, 1.2))
y <- f(x, z = 1)
m <- lm(y~x)
x_new <- seq(0,2.2,length.out=100)
newdata <- data.frame(x = x_new, true = f(x_new, z = 1, e = 0))
p <- predict(m, newdata, interval = "prediction")
ylim <- range(p)
ylim <- c(min(newdata$true),max(newdata$true))
xlim <- c(0.1,2.1)
xlab <- "predictor"
ylab <- "response"

pdf("../figures/concept_figures/fig1.pdf",width=10,height=5)
par(mfrow = c(1,2 ))
par(mar = c(5.1, 4.1, 2.1, 0.1))
plot(y~x, xlim = xlim, ylim = ylim, xlab = xlab, ylab = ylab,pch=16)
newdata <- cbind(newdata, p)
lines(true~x, newdata, col = 'green')
lines(fit~x, newdata, col = 'black')
lines(lwr~x, newdata, lty = 2, col = 'black')
lines(upr~x, newdata, lty = 2, col = 'black')
legend("topleft",legend="a",bty="n")
legend("bottomright",lty=c(1,2,1,NA),pch=c(NA,NA,NA,16),
       col=c("black","black","green","black"),
       legend=c("prediction","interval","truth","training"),bty="n")

# simulate example data for a random forest model:
f <- function(x){
  wave.1 <- sin(3*x)+1
  wave.2 <- sin(12*x)+1
  wave.3 <- 0.9 * wave.1 + 0.25 * wave.2
}

x <- seq(0,2.2,0.001)
newdata <- data.frame("x"=x,"true" = f(x))
set.seed(1)
x <- c(runif(10,0,0.4),runif(18,0.8,1.5),runif(11,1.5,1.7))
set.seed(10)
y <- f(x)+runif(length(x),-0.1,0.1)


ylim <- c(min(newdata$true),max(newdata$true))
xlim <- c(0.1,2.1)

#### Random Forest with predictions from individual trees
set.seed(10)
rf <- randomForest(y~x, data.frame(x=x,y=y))
pr <- predict(rf, newdata, predict.all = TRUE)
par(mar = c(5.1, 1.1, 2.1, 2.1))
plot(y~x,xlim=xlim,ylim=ylim,xlab = xlab, ylab = NA,yaxt="n",pch=16)
lines(true~x, newdata, col = 'green')
lines(pr$aggregate~newdata$x, col = 'black')
lwr <- apply(pr$individual, 1, quantile, 0.025)
upr <- apply(pr$individual, 1, quantile, 0.975)
lines(lwr~newdata$x, col = 'black', lty = 2)
lines(upr~newdata$x, col = 'black', lty = 2)
legend("topleft",legend="b",bty="n")

### Quantile regression forest
#set.seed(10)
#qrf <- quantregForest(data.frame(x),y)
#pr  <- predict(qrf,  newdata)
#par(mar = c(5.1, 1.1, 2.1, 2.1))
#plot(y~x,xlim=xlim,ylim=ylim,xlab = xlab, ylab = NA,yaxt="n",pch=16)
#lines(true~x, newdata, col = 'green')
#lines(pr[,2]~newdata$x, col = 'black')
#lines(pr[,1]~newdata$x, col = 'black', lty = 2)
#lines(pr[,3]~newdata$x, col = 'black', lty = 2)
#legend("topleft",legend="b",bty="n")

dev.off()
```

```{r figsPredIntervals, echo=FALSE,out.width="100%",fig.cap="Problem of predicting beyond the training data and behaviour of prediction intervals for different models. Left: linear regression prediction interval width increases with distance from the center of the training data, right: a more complex relationship fitted with Random Forest. Prediction beyond the training data becomes highly unreliable, although prediction interval width outside the data range is constant. Random Forest prediction intervals were obtained by computing quantiles over the predictions from individual trees."}
include_graphics("../figures/concept_figures/fig1.pdf")
```

# Method of the DI and AOA estimation


```{r data, message = FALSE,include = FALSE}

# get example data from Worldclim:
predictors_global <- getData('worldclim', var='bio', res=10, path='../data/')
wp <- extent(studyarea)
predictors <- crop(predictors_global,wp)

#create a mask for land area:
mask <- predictors[[1]]
values(mask)[!is.na(values(mask))] <- 1

# create a virtual response:
response <- generateSpFromPCA(predictors[[simulateResponse]],
                              means = meansPCA,sds = sdPCA, plot=F)$suitab.raster
mask <- rasterToPolygons(mask,dissolve=TRUE)

#simulate sample data:
set.seed(seed)
samplepoints <- spsample(mask,npoints,"random")

# compile training data set:
trainDat <- extract(predictors,samplepoints,df=TRUE)
trainDat <- trainDat[,c(var1,var2)]
names(trainDat) <- c("A","B")
trainDat$response <- extract (response,samplepoints)

```

```{r model,include = FALSE}
# train a model:
set.seed(seed)
folds <- createFolds(trainDat$response,k=3,returnTrain = TRUE)
set.seed(seed)
model <- train(trainDat[,c("A","B")],trainDat$response,
               trControl = trainControl(method="cv",index=folds,savePredictions = TRUE),
               importance=T)
weights <- t(varImp(model,scale=F)$importance)
```

```{r newdat,include = FALSE}
newdat_orig <- data.frame("A"=seq(min(values(predictors[[var1]]),na.rm=T),max(values(predictors[[var1]]),na.rm=T),length.out=100),
                          "B"=seq(min(values(predictors[[var2]]),na.rm=T),max(values(predictors[[var2]]),na.rm=T),length.out=100))



newdat_orig <- data.frame("A"=seq(min(trainDat$A)-0.7*mean(trainDat$A),
                                  max(trainDat$A)+0.7*mean(trainDat$A),
                                  length.out = 100),
                          "B"=seq(min(trainDat$B)-0.7*mean(trainDat$B),
                                  max(trainDat$B)+0.7*mean(trainDat$B),
                                  length.out = 100))

newdat_orig <- expand.grid(newdat_orig[,1],newdat_orig[,2])
names(newdat_orig) <- c("A","B")


newdat_pred <- predict(model,newdat_orig)
newdat_aoa <- aoa(newdat_orig,model)
alldat <- data.frame(newdat_orig,"pred"=newdat_pred,
                     "aoa"=data.frame("DI"=newdat_aoa$DI,"AOA"=newdat_aoa$AOA))

trainDat_scaled<- scale(trainDat[,c("A","B")])
scaleparam <- attributes(trainDat_scaled)
newdat_scaled <- scale(newdat_orig,center=scaleparam$`scaled:center`,                   scale=scaleparam$`scaled:scale`)

trainDat_weights <- data.frame(trainDat_scaled[,"A"]*weights[,"A"],
                               trainDat_scaled[,"B"]*weights[,"B"])
names(trainDat_weights) <- c("A","B")
newdat <- newdat_scaled
newdat[,"A"] <- newdat_scaled[,"A"]*weights[,"A"]
newdat[,"B"] <- newdat_scaled[,"B"]*weights[,"B"]

newpoint <- 4010
```

## Create Sample data, scale and weight them


```{r Fig_weightedData,include = FALSE}
pdf("../figures/concept_figures/weightedData.pdf",width=11,height=5.5)

par(fig=c(0,0.49,0,1), new=TRUE,mar=c(4,4,4,4))
plot(trainDat[,"A"],trainDat[,"B"],pch=16,
     xlim=c(min(newdat_orig[,"A"]),max(newdat_orig[,"A"])),
     ylim=c(min(newdat_orig[,"B"]),max(newdat_orig[,"B"])),
     xlab="Predictor A",ylab="Predictor B")
legend("topleft",pch=c(16,4),col=c("black"),legend=
         c("Training samples"),bty="n")

par(new = TRUE)
plot(trainDat_scaled[,"A"],
     trainDat_scaled[,"B"],pch=16,xlab="",ylab="",
     xlim=c(min(newdat_scaled[,"A"]),max(newdat_scaled[,"A"])),
     ylim=c(min(newdat_scaled[,"B"]),max(newdat_scaled[,"B"])),axes=F)
Axis(side = 3, x = trainDat_scaled[,"A"])
Axis(side = 4, x = trainDat_scaled[,"B"],las=1)
mtext("Predictor A (scaled)", side = 3,line=3)

corners = par("usr")
par(xpd = TRUE) #Draw outside plot area
text(x = corners[2]+1, y = mean(corners[3:4]), "Predictor B (scaled)", srt = 270,line=3)


par(fig=c(0.51,1,0,1),new=TRUE,mar=c(4,4,4,4))
plot(trainDat_weights[,"A"],
     trainDat_weights[,"B"],
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),
     xlab="Predictor A (scaled and weighted)",ylab="Predictor B (scaled and weighted)",pch=16,asp=1)


par(mgp=c(1,0.4,0))
par(fig=c(0.54,0.79,0.6,0.97), new=TRUE)
barplot(unlist(t(data.frame(varImp(model,scale=F)$importance))),horiz=T,xlab="",cex.axis=0.75,cex.names=0.75)
title(xlab="Importance", line=1.2,cex.lab=0.75,adj=0)
dev.off()
```

```{r figs1, echo=FALSE,out.width="100%",fig.cap="Initial situation: Training samples in a multidimensional (here 2) predictor space (a). First, the predictor space is scaled (second x and y axis in the left plot) and then weighted (plot right) according to the estimated variable importance shown in the topleft corner."}
include_graphics("../figures/concept_figures/weightedData.pdf")
```




## Calculate the DI within the training data to get the threshold for the AOA

```{r prep,include=FALSE}
### DI of training data
cols_fold <- c("blue","green","orange")
firstpoint <- 23

trainDat_weights$fold <- substr(model$pred$Resample,5,5)[order(model$pred$rowIndex)]
tmp <- NA
for (i in 1:nrow(trainDat_weights[,1:2])){
  mindist <- dist(rbind(trainDat_weights[firstpoint,1:2],trainDat_weights[i,1:2]))
  if(trainDat_weights$fold[firstpoint]==trainDat_weights$fold[i]){
    mindist <- NA
  }
  mindist <- pmin(mindist,tmp,na.rm=T)
  if(i>1&&mindist<tmp){
    whichIsMin_tr <- i
  }
  tmp <- mindist
}

### estimate mean distance between all points:
trainDist_mean <- c()
trainDist_min <- c()
for (i in 1:nrow(trainDat_weights)){
  trainDist <- FNN::knnx.dist(trainDat_weights[i,c("A","B")],trainDat_weights[,c("A","B")],k=1)
  trainDist[i] <- NA
  if (!is.null(folds)){
    trainDist[trainDat_weights$fold==trainDat_weights$fold[i]] <- NA
  }
  trainDist_mean <- c(trainDist_mean,mean(trainDist,na.rm=T))
  trainDist_min <- c(trainDist_min,min(trainDist,na.rm=T))
}


### calculate the DI of a new data point
tmp <- NA
for (i in 1:nrow(trainDat_weights[,1:2])){
  mindist_new <- dist(rbind(newdat[newpoint,1:2],trainDat_weights[i,1:2]))
  mindist_new <- pmin(mindist_new,tmp,na.rm=T)
  if(i>1&&mindist_new<tmp){
    whichIsMin <- i
  }
  tmp <- mindist_new
}
```




```{r Fig_DIOfTraining,include = FALSE}

pdf("../figures/concept_figures/DI_training.pdf",width=15,height=5.7)
par(fig=c(0,0.355,0,1), new=TRUE,mar=c(4,4,1,1))
plot(trainDat_weights[,"A"],
     trainDat_weights[,"B"],
     col="black",
     pch=16,xlab="Predictor A (scaled and weighted)",ylab="Predictor B (scaled and weighted)",
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),asp=1)

points(trainDat_weights[firstpoint,"A"],trainDat_weights[firstpoint,"B"],pch=1,col="red")
mtext("a", 2, adj=2, las=1,padj=-19)


for (i in 1:nrow(trainDat_weights)){
  
  lines(c(trainDat_weights[firstpoint,"A"],trainDat_weights[i,"A"]),
        c(trainDat_weights[firstpoint,"B"],trainDat_weights[i,"B"]),
        col="grey")
}
points(trainDat_weights[,"A"],
       trainDat_weights[,"B"],
       #col=cols_fold[as.numeric(trainDat_weights$fold)],
       col="black",
       pch=16)

points(trainDat_weights[firstpoint,"A"],trainDat_weights[firstpoint,"B"],pch=1,col="red")


legend("topleft",pch=c(16,1),col=c("black","red"),legend=c("Training samples","Example"),bty="n")

legend("topright",legend=paste0("Mean distance for example =", round(
  trainDist_mean[firstpoint],2),"\nAverage mean distance between\nall training data =",round(newdat_aoa$parameters$trainDist_avrgmean,2)),bty="n",cex=0.7)



#par(fig=c(0,0.7,0,0.7), new=TRUE)
par(fig=c(0.355,0.68,0,1),new=TRUE,mar=c(4,1,1,1))
plot(trainDat_weights[,"A"],
     trainDat_weights[,"B"],col=cols_fold[as.numeric(trainDat_weights$fold)],pch=16,xlab="Predictor A (scaled and weighted)",ylab="",
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),asp=1,yaxt="n")
mtext("b", 2, adj=2, las=1,padj=-19)
points(trainDat_weights[firstpoint,"A"],trainDat_weights[firstpoint,"B"],pch=1,col="red")

lines(c(trainDat_weights[firstpoint,"A"],trainDat_weights[whichIsMin_tr,"A"]),
      c(trainDat_weights[firstpoint,"B"],trainDat_weights[whichIsMin_tr,"B"]))
text(trainDat_weights[whichIsMin_tr,"A"],trainDat_weights[whichIsMin_tr,"B"],paste0("dist=",round(mindist,2),", \nDI= ",round(mindist/newdat_aoa$parameters$trainDist_avrgmean,2)),pos=2,cex=0.85)

legend("topleft",pch=c(rep(16,3),1),col=c(cols_fold,"red"),legend=c("Fold 1","Fold 2","Fold 3","Example"),bty="n")




par(fig=c(0.57,0.68,0.44,1), new=TRUE)

par(mgp=c(1,0.49,0))

boxplot(newdat_aoa$parameters$trainDI,cex.axis=0.6,cex.lab=0.5,ylab="",yaxt="n")
axis(side = 2, at = c(0,0.2,0.4,0.6),cex.axis=0.7)
abline(boxplot.stats(newdat_aoa$parameters$trainDI)$stats[5],0,col=alpha("blue",0.5),lwd=2)
title(ylab="DI of training data", line=1.5,cex.lab=0.6)
text(0.7,boxplot.stats(newdat_aoa$parameters$trainDI)$stats[5],
     "AOA\nthreshold",pos=3,col=alpha("blue",0.5),cex=0.7)




par(fig=c(0.68,1,0,1),new=TRUE,mar=c(4,1,1,1),mgp=c(3, 1, 0))    


plot(trainDat_weights[,"A"],
     trainDat_weights[,"B"],pch=16,xlab="Predictor A (scaled and weighted)",ylab="",
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),asp=1,yaxt="n")
mtext("c", 2, adj=2, las=1,padj=-19)

lines(c(newdat[newpoint,"A"],trainDat_weights[whichIsMin,"A"]),
      c(newdat[newpoint,"B"],trainDat_weights[whichIsMin,"B"]))
points(newdat[newpoint,"A"],newdat[newpoint,"B"],pch=4,col="red")
text(newdat[newpoint,"A"],newdat[newpoint,"B"],
     paste0("dist=",round(mindist_new,2),", \nDI=",round(mindist_new/newdat_aoa$parameters$trainDist_avrgmean,2)),pos=2,cex=0.85)


legend("topleft",pch=c(16,4),col=c("black","red"),legend=c("Training samples","A new data point"),bty="n")



dev.off()
```


```{r figs3, echo=FALSE,out.width="100%",fig.cap="Training samples in a multi-dimensional (here 2-dimensional) predictor space that has been scaled and weighted. First, the average of the mean distances between all training data is calculated (a). Next, the DI of the training data is calculated. For each training data point (shown here for one example), the distance to the nearest training data point not located in the same cross-validation fold is calculated (here visualized assuming a 3-fold cross-validation)(b). This distance is divided by the average of the mean distances between all training data (a) to derive the DI. The DI is calculated for each training data point (boxplot in b) and the threshold for the AOA is then derived from the upper whisker of the DI values. For a new data point, the DI is calculated accordingly (c). In this example, the DI is larger than the DI-threshold, indicating that this new data point falls outside the AOA."}
include_graphics("../figures/concept_figures/DI_training.pdf")
```


## Estimate the AOA for each new potential data point

```{r Fig_DI_and_AOA,include = FALSE}

pdf("../figures/concept_figures/AOA.pdf",width=10,height=5.5)
par(mfrow=c(1,2))
alldat$order = findInterval(alldat$aoa.DI, sort(alldat$aoa.DI))

plot(alldat$A,alldat$B,pch=15,col=viridis(nrow(alldat))[alldat$order],
     xlab="Predictor A",ylab="Predictor B",
     xlim=c(min(newdat_orig[,"A"]),max(newdat_orig[,"A"])),
     ylim=c(min(newdat_orig[,"B"]),max(newdat_orig[,"B"])))
text(285,600,"DI",cex = 0.75)
color.legend(275,400,300,570,round(c(min(alldat$aoa.DI),alldat$aoa.DI[alldat$order==nrow(alldat)*0.5],alldat$aoa.DI[alldat$order==nrow(alldat)*0.75],max(alldat$aoa.DI)),1),
             viridis(nrow(alldat))[c(1,nrow(alldat)*0.5,nrow(alldat)*0.75,nrow(alldat))],gradient="y",cex = 0.75)


points(trainDat[,"A"],trainDat[,"B"],pch=16)
legend("topleft",pch=c(16),col=c("black"),legend=c("Training samples"),bty="n")

plot(alldat$A,alldat$B,pch=15,col=viridis(nrow(alldat))[alldat$order],
     xlab="Predictor A",ylab="Predictor B",
     xlim=c(min(newdat_orig[,"A"]),max(newdat_orig[,"A"])),
     ylim=c(min(newdat_orig[,"B"]),max(newdat_orig[,"B"])))
points(alldat$A,alldat$B,pch=16,col=c("white","transparent")[alldat$aoa.AOA+1],cex=1.1)
text(285,600,"DI",cex = 0.75)
color.legend(275,400,300,570,round(c(min(alldat$aoa.DI),alldat$aoa.DI[alldat$order==nrow(alldat)*0.5],alldat$aoa.DI[alldat$order==nrow(alldat)*0.75],max(alldat$aoa.DI)),1),
             viridis(nrow(alldat))[c(1,nrow(alldat)*0.5,nrow(alldat)*0.75,nrow(alldat))],gradient="y",cex = 0.75)

points(trainDat[,"A"],trainDat[,"B"],pch=16)
legend("topleft",pch=c(16),col=c("black"),legend=c("Training samples"),bty="n")

dev.off()
par(mfrow=c(1,1))
```


```{r figs4, echo=FALSE,out.width="100%",fig.cap="The AOA threshold can be applied to the predictor space of the entire area of interest to derive the AOA (b) from the DI (a) of each new data point which is to be predicted. Areas shown in white in b are outside the AOA."}
include_graphics("../figures/concept_figures/AOA.pdf")
```



## Using the DI to quantitatively express prediction uncertainty

### Estimating the relationship using the cross-validated data


```{r, include=FALSE}
pdf("../figures/concept_figures/AOA_calib_singleCV.pdf",width=10,height=7)
singleCVAOA <- calibrate_aoa(newdat_aoa,model,window.size = 10)
invisible(dev.off())
```



```{r, echo=FALSE,out.width="75%",fig.cap="Relationship between the DI and RMSE within the AOA based on single cross-validation. RMSE was calculated in a sliding window (here: size of 10) along the DI. To estimate the RMSE based on the DI, a shape constrained additive model was used. Note that in this small example there is no strong relationship between DI and RMSE. Please see the paper for a more meaningful example."}
include_graphics("../figures/concept_figures/AOA_calib_singleCV.pdf")
```





### Using Multi-purpose CV

The results shown above are based on a single-purpose CV.
We can also estimate the relationship between performance and DI using multiple CVs.
Here, we split the data several times into folds using clusters in the predictor space with the number of clusters ranging between 3 and the number of data points (=LOOCV).
The following figure shows how data splitting can look like for different numbers of k.

```{r, warning= FALSE, echo = FALSE}

pdf("../figures/concept_figures/MultiCVsplits.pdf",width=10,height=4)
par(mfrow=c(1,3),mar=c(4,4,1,1))
k <- 4
clstr <- kmeans(trainDat_weights,centers = k)
plot(trainDat_weights$A,trainDat_weights$B,col=rainbow(k)[clstr$cluster],
     pch=16,xlab="Predictor A (scaled and weighted)",ylab="Predictor B (scaled and weighted)",
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),asp=1)
legend("topleft",legend=paste0("k=",k),bty="n")

k <- 10
clstr <- kmeans(trainDat_weights,centers = k)
plot(trainDat_weights$A,trainDat_weights$B,col=rainbow(k)[clstr$cluster],
     pch=16,xlab="Predictor A (scaled and weighted)",ylab="",
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),asp=1)
legend("topleft",legend=paste0("k=",k),bty="n")

k <- nrow(trainDat_weights)-1
clstr <- kmeans(trainDat_weights,centers = k)
plot(trainDat_weights$A,trainDat_weights$B,col=rainbow(k)[clstr$cluster],
     pch=16,xlab="Predictor A (scaled and weighted)",ylab="",
     xlim=c(min(newdat[,"A"]),max(newdat[,"A"])),
     ylim=c(min(newdat[,"B"]),max(newdat[,"B"])),asp=1)
legend("topleft",legend=paste0("k=",k),bty="n")
invisible(dev.off())

```


```{r, echo=FALSE,out.width="100%",fig.cap="Example of multi-purpose cross-validation folds where data are split into folds (colors) based on clusters in the predictor space. This is done for different number of clusters, here shown for k=4, k=10, and k=149."}
include_graphics("../figures/concept_figures/MultiCVsplits.pdf")
```


Using multi-purpose CVs allows expanding the AOA and also allows giving a more robust estimate for the relationship. The relationship can be used to estimate the DI-dependent prediction performance for each new data point based on its DI.

```{r, warning= FALSE, echo=FALSE}
pdf("../figures/concept_figures/AOA_calib_multiCV.pdf",width=10,height=7)
multiCVAOA <- calibrate_aoa(newdat_aoa,model,window.size = 25,multiCV = TRUE)
invisible(dev.off())
```


```{r, echo=FALSE,out.width="75%",fig.cap="Relationship between the DI and RMSE within the AOA based on multi-purpose cross-validation. RMSE was calculated in a sliding window (here size of 25. Due to multiple cross-validations more data points are available which allows for a larger window size) along the DI. To estimate the RMSE based on the DI, a shape constrained additive model was used. Note that in this small example there is no strong relationship between DI and RMSE. Please see the paper for a more meaningful example."}
include_graphics("../figures/concept_figures/AOA_calib_multiCV.pdf")
```



# FAQ explained in figures

## What happens if the full range of predictors is covered by training data?

When the full range of environmental conditions is covered the result is that the model can be applied to the entire study area. However, covering the full range of each variable is not enough (figure left) but the combined ranges need to be covered if the model should be applicable to the entire study area (figure right).

```{r Fig_rangecovered,include = FALSE}

pdf("../figures/concept_figures/fullgradientcovered.pdf",width=9,height=5)
par(mfrow=c(1,2))

grid <- expand.grid("x"=seq(0,11,0.1),"y"=seq(0,11,0.1))
smpl <- data.frame("x"=c(1:10,rep(1,9)),"y"=c(rep(1,9),1:10))
AOA <- aoa(grid,train = smpl)

plot(grid,col=AOA$AOA,pch=15,yaxs="i",xaxs="i",
     xlab="Predictor A",ylab="Predictor B")
points(smpl,col="red",pch=15)
legend("topright",pt.bg=c("black","white","red"),
       legend=c("inside AOA","ouside AOA","training data"),
       pch=22,col="black")

smpl <-  expand.grid("x"=seq(1,10,3),"y"=seq(1,10,3))
AOA <- aoa(grid,train = smpl)

plot(grid,col=AOA$AOA,pch=15,yaxs="i",xaxs="i",
     xlab="Predictor A",ylab="Predictor B")
points(smpl,col="red",pch=15)
legend("topright",pt.bg=c("black","white","red"),
       legend=c("inside AOA","ouside AOA","training data"),
       pch=22,col="black",bg = "white")
dev.off()
```

```{r figs_fullgradient, echo=FALSE,out.width="70%",fig.cap=""}
include_graphics("../figures/concept_figures/fullgradientcovered.pdf")
```

## Why can't we use the distance to all data points, or hulls, instead of distance to the nearest neighbor?

The distance to all training points is not helpful here because gaps could not be considered. But gaps are equally problematic (see our first figure in the manuscript) and using the average distance to training points cannot account for that. In the example below the new data point even has a lower average distance to training data although it is clearly in an area not covered by training data. The problem is similar for hulls, that do not take gaps in the predictor space into account.  

```{r Fig_dist2all,include = FALSE}

pdf("../figures/concept_figures/dist2allpoints.pdf",width=7,height=7)
dat <- data.frame("x"=c(runif(100,1,10),runif(100,9,10),runif(100,1,10),runif(100,1,2)),
                  "y"=c(runif(100,1,2),runif(100,1,10),runif(100,9,10),runif(100,1,10)))
plot(dat$x,dat$y,xlim=c(0,11),ylim=c(0,11),xlab="Predictor A",ylab="Predictor B")
points(5.5,5.5,pch=4,col="red",cex=3)
legend("topleft",pch=c(1,4),legend=c("training data","new data point"),
       col=c("black","red"),bty="n")
legend("topright",legend=paste0("mean distance between points = ",round(mean(dist(dat)),2)),bty="n")

dist_new <- mean(FNN::knnx.dist(data.frame("x"=5.5,"y"=5.5),dat,k=1))
text(5.5,5.5,paste0("mean distance to all \ntrainig points = ",round(dist_new,2)),pos=1)
dev.off()
```


```{r figs_dist2allpoints, echo=FALSE,out.width="50%",fig.cap=""}
include_graphics("../figures/concept_figures/dist2allpoints.pdf")
```

## How would the AOA look like for Fig. 1 of the manuscript?

```{r Fig_predintervalsAOA,include = FALSE}
AOA <- aoa(newdata, train=data.frame("x"=x))

pdf("../figures/concept_figures/fig_last.pdf",width=6,height=8)
par(mfrow=c(2,1))
par(mar = c(0.1, 5.1, 2.1, 0.1))
plot(y~x,xlim=xlim,ylim=ylim,xlab = NA, xaxt='n',
     ylab = ylab,pch=16)
lines(true~x, newdata, col = 'green')
lines(pr$aggregate~newdata$x, col = 'black')
lwr = apply(pr$individual, 1, quantile, 0.025)
upr = apply(pr$individual, 1, quantile, 0.975)
lines(lwr~newdata$x, col = 'black', lty = 2)
lines(upr~newdata$x, col = 'black', lty = 2)

bp <-which(c(FALSE, tail(AOA$AOA,-1) != head(AOA$AOA,-1)))
polygon(x=c(newdata$x[bp[1]],newdata$x[bp[2]],newdata$x[bp[2]],newdata$x[bp[1]]),
        y=c(0,0,2.3,2.3),col=rgb(0.6,0.6,0.6,alpha=0.5),border = NA)

polygon(x=c(newdata$x[bp[3]],max(newdata$x)-0.022,max(newdata$x)-0.022,newdata$x[bp[3]]),
        y=c(0,0,2.3,2.3),col=rgb(0.6,0.6,0.6,alpha=0.5),
        border = NA)

legend("bottomleft",lty=c(1,2,1,NA,NA),pch=c(NA,NA,NA,16,15),
       col=c("black","black","green","black","grey"),
       legend=c("prediction","interval","truth","training","not in AOA")
       ,bty="n",bg="white")
legend("topleft",legend="a",bty="n")

par(mar = c(6, 5.1, 0.7, 0.1))
plot(AOA$DI~newdata$x,xlim=xlim,xlab = xlab, ylab = "DI",
     type="l",lwd=2)
abline(newdat_aoa$parameters$threshold,0,lty=2)
legend("topleft",legend="b",bty="n")
dev.off()
```

```{r figsPredIntervalsAOA, echo=FALSE,out.width="75%",fig.cap="Hypothetical example of a relationship between a virtual predictor and response variable as well as the predictions made by Random Forest already presented in Figure 1. Low values in the dissimilarity index (DI) do not necessarily mean that the prediction error is high. As moving away from the last training data point (x= 1.7), the value of the DI increases (b). However, the error does not necessarily increases in the same way (comparing the predictions with the truth in a). The uncertainty must still be considered as very high because this area of the predictor space is unknown to the model. The area of applicability (AOA) is derived using the outlier-removed maximum DI observed in the cross-validated training data as a threshold (dashed line in b) and is used to exclude predictions in areas where dissimilarity is too high (grey area in a)."}
include_graphics("../figures/concept_figures/fig_last.pdf")
```
